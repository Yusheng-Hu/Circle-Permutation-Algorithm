name: Circle Permutation Benchmark

on:
  push:
    branches: [ "main" ]
  workflow_dispatch:

jobs:
  benchmark:
    name: Run Circle Permutation Profiling
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Get Environment & Metadata
        run: |
          MODEL=$(lscpu | grep "Model name" | cut -d':' -f2 | xargs)
          N_VAL=$(grep "#define N " Circle_Permutation_Algorithm.cpp | awk '{print $3}')
          echo "CPU_MODEL=$MODEL" >> $GITHUB_ENV
          echo "CURRENT_N=$N_VAL" >> $GITHUB_ENV

      - name: Compile
        run: |
          g++ -O3 -std=c++11 -march=native -flto -ffast-math -fomit-frame-pointer \
          Circle_Permutation_Algorithm.cpp -o circle_test -pthread

      - name: Execute
        run: |
          ./circle_test | tee run_log.txt
          TIME_VAL=$(grep "RESULT_TIME" run_log.txt | awk '{print $2}')
          CHECK_VAL=$(grep "CHECKSUM_COUNT" run_log.txt | awk '{print $2}')
          echo "TIME_CIRCLE=$TIME_VAL" >> $GITHUB_ENV
          echo "CHECKSUM=$CHECK_VAL" >> $GITHUB_ENV

      - name: Generate Summary Report
        if: always()
        run: |
          {
            echo "### ðŸš€ Performance Benchmark Report (N=${{ env.CURRENT_N }})"
            echo ""
            echo "| Metric | Value |"
            echo "| :--- | :--- |"
            echo "| **N (Input Size)** | ${{ env.CURRENT_N }} |"
            echo "| **Execution Time** | \`${{ env.TIME_CIRCLE }} s\` |"
            echo "| **Checksum (Perms)** | \`${{ env.CHECKSUM }}\` |"
            echo "| **Status** | Completed |"
            echo ""
            echo "#### ðŸ’» Environment Information"
            echo "- **CPU Model:** ${{ env.CPU_MODEL }}"
            echo "- **Optimization Flags:** \`-O3 -march=native -flto\`"
          } >> $GITHUB_STEP_SUMMARY
